{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f5574",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a3444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trieste\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from util import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trieste.objectives.multi_objectives import VLMOP2\n",
    "from trieste.objectives.utils import mk_observer\n",
    "from trieste.observer import OBJECTIVE\n",
    "from trieste.data import Dataset\n",
    "from trieste.models.gpflow.models import GaussianProcessRegression\n",
    "\n",
    "from trieste.acquisition import BatchMonteCarloExpectedHypervolumeImprovement\n",
    "from trieste.acquisition.rule import EfficientGlobalOptimization\n",
    "from trieste.bayesian_optimizer import BayesianOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b6cfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trieste.acquisition.multi_objective.pareto import Pareto, get_reference_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33d100",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mo_lp.gpr_stack import GPRStack\n",
    "from mo_lp.mo_penalization import MOLocalPenalizationAcquisitionFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6446d9ec",
   "metadata": {},
   "source": [
    "## 1d case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = trieste.space.Box([0], [2*math.pi])\n",
    "\n",
    "def f1(x):\n",
    "    return tf.cos(2 * x) + tf.sin(x)\n",
    "\n",
    "def f2(x):\n",
    "    return 0.2 * (tf.cos(x) - tf.sin(x)) + 0.3\n",
    "\n",
    "def f(x):\n",
    "    return tf.concat([f1(x), f2(x)], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e501f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plot = np.linspace(start=search_space.lower[0], stop=search_space.upper[0], num=100)\n",
    "\n",
    "plt.plot(x_plot, f1(x_plot), label=\"f1\");\n",
    "plt.plot(x_plot, f2(x_plot), label=\"f2\");\n",
    "plt.legend();\n",
    "plt.title(\"Actual functions\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a297ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_stacked_independent_objectives_model(data: Dataset):\n",
    "    gprs = []\n",
    "    for idx in range(2):\n",
    "        single_obj_data = Dataset(\n",
    "            data.query_points, tf.gather(data.observations, [idx], axis=1)\n",
    "        )\n",
    "        variance = tf.math.reduce_variance(single_obj_data.observations)\n",
    "        kernel = gpflow.kernels.Matern52(variance, tf.constant(0.2, tf.float64))\n",
    "        gpr = gpflow.models.GPR(single_obj_data.astuple(), kernel, noise_variance=1e-5)\n",
    "        gpflow.utilities.set_trainable(gpr.likelihood, False)\n",
    "        gprs.append((GaussianProcessRegression(gpr), 1))\n",
    "\n",
    "    return GPRStack(*gprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "observer = mk_observer(f, OBJECTIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41199527",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_initial_points = 5\n",
    "initial_query_points = search_space.sample(num_initial_points)\n",
    "initial_data = observer(initial_query_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0373ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_stacked_independent_objectives_model(initial_data[OBJECTIVE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b51756",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 3\n",
    "num_query_points=4\n",
    "\n",
    "acq_function = BatchMonteCarloExpectedHypervolumeImprovement(sample_size=250).using(OBJECTIVE)\n",
    "acq_rule = EfficientGlobalOptimization(acq_function, num_query_points=num_query_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = BayesianOptimizer(observer, search_space).optimize(num_steps, initial_data, {OBJECTIVE: model}, acq_rule)\n",
    "dataset = result.try_get_final_datasets()[OBJECTIVE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = result.try_get_final_models()[OBJECTIVE]._models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d2191",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_query_points = dataset.query_points\n",
    "f1_model_values, _ = models[0].predict(all_query_points)\n",
    "f2_model_values, _ = models[1].predict(all_query_points)\n",
    "\n",
    "points_in_objective_space = tf.concat([f1_model_values, f2_model_values], axis=1)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=num_initial_points)\n",
    "plt.xlabel(\"f1\");\n",
    "plt.ylabel(\"f2\");\n",
    "plt.title(\"Discovered Pareto front\");\n",
    "plt.show();\n",
    "\n",
    "\n",
    "\n",
    "points_in_objective_space = tf.stack([f1(x_plot), f2(x_plot)], axis=-1)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=0)\n",
    "plt.xlabel(\"f1\");\n",
    "plt.ylabel(\"f2\");\n",
    "plt.title(\"True Pareto front\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851dbd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_function = MOLocalPenalizationAcquisitionFunction().using(OBJECTIVE)\n",
    "acq_rule = EfficientGlobalOptimization(acq_function, num_query_points=num_query_points)\n",
    "model = build_stacked_independent_objectives_model(initial_data[OBJECTIVE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe86378",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = BayesianOptimizer(observer, search_space).optimize(num_steps, initial_data, {OBJECTIVE: model}, acq_rule)\n",
    "dataset = result.try_get_final_datasets()[OBJECTIVE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b09214",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = result.try_get_final_models()[OBJECTIVE]._models\n",
    "\n",
    "all_query_points = dataset.query_points\n",
    "f1_model_values, _ = models[0].predict(all_query_points)\n",
    "f2_model_values, _ = models[1].predict(all_query_points)\n",
    "\n",
    "points_in_objective_space = tf.concat([f1_model_values, f2_model_values], axis=1)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=num_initial_points)\n",
    "plt.xlabel(\"f1\");\n",
    "plt.ylabel(\"f2\");\n",
    "plt.title(\"Discovered Pareto front\");\n",
    "plt.show();\n",
    "\n",
    "\n",
    "\n",
    "points_in_objective_space = tf.stack([f1(x_plot), f2(x_plot)], axis=-1)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=0)\n",
    "plt.xlabel(\"f1\");\n",
    "plt.ylabel(\"f2\");\n",
    "plt.title(\"True Pareto front\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e699984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from true_pf.generate_true_pareto_fronts import read_true_pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from true_pf.generate_true_pareto_fronts import SIMPLE_1D_INPUT_FILENAME\n",
    "\n",
    "ref_point = get_reference_point(dataset.observations)\n",
    "true_pf = read_true_pf(os.path.join(\"true_pf\", SIMPLE_1D_INPUT_FILENAME))\n",
    "ideal_hv = Pareto(true_pf).hypervolume_indicator(ref_point)\n",
    "\n",
    "hv_regret = []\n",
    "for i in range(num_initial_points+1, len(dataset.observations)):\n",
    "    observations = dataset.observations[:i, :]\n",
    "    observed_hv = Pareto(observations).hypervolume_indicator(ref_point)\n",
    "\n",
    "    hv_regret.append((ideal_hv - observed_hv).numpy())\n",
    "\n",
    "hv_regret = np.array(hv_regret)\n",
    "print(hv_regret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc50cc",
   "metadata": {},
   "source": [
    "## 2d case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50140eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = trieste.space.Box([0, 0], [2*math.pi, 2*math.pi])\n",
    "\n",
    "def f1(input_data):\n",
    "    x, y = input_data[..., -2], input_data[..., -1]\n",
    "    z = tf.cos(2.0 * x) * tf.cos(y) + tf.sin(x)\n",
    "    return z[:, None]\n",
    "\n",
    "def f2(input_data):\n",
    "    x, y = input_data[:, -2], input_data[:, -1]\n",
    "    # changes are made so that the function is between 0 and 1\n",
    "    z = 1.0 - (tf.cos(x) * tf.cos(y) - tf.sin(x) * tf.sin(y) + 1.0) / 2.0\n",
    "    return z[:, None]\n",
    "\n",
    "def f(x):\n",
    "    return tf.concat([f1(x), f2(x)], axis=-1)\n",
    "\n",
    "observer = mk_observer(f, OBJECTIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371a586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_initial_points = 5\n",
    "initial_query_points = search_space.sample(num_initial_points)\n",
    "initial_data = observer(initial_query_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec69184",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_stacked_independent_objectives_model(initial_data[OBJECTIVE])\n",
    "\n",
    "num_steps = 10\n",
    "num_query_points=4\n",
    "\n",
    "acq_function = BatchMonteCarloExpectedHypervolumeImprovement(sample_size=250).using(OBJECTIVE)\n",
    "acq_rule = EfficientGlobalOptimization(acq_function, num_query_points=num_query_points)\n",
    "\n",
    "result = BayesianOptimizer(observer, search_space).optimize(num_steps, initial_data, {OBJECTIVE: model}, acq_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ae803",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = result.try_get_final_datasets()[OBJECTIVE]\n",
    "models = result.try_get_final_models()[OBJECTIVE]._models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_query_points = dataset.query_points\n",
    "f1_model_values, _ = models[0].predict(all_query_points)\n",
    "f2_model_values, _ = models[1].predict(all_query_points)\n",
    "\n",
    "points_in_objective_space = tf.concat([f1_model_values, f2_model_values], axis=1)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=num_initial_points)\n",
    "plt.xlabel(\"f1\");\n",
    "plt.ylabel(\"f2\");\n",
    "plt.title(\"Discovered Pareto front\");\n",
    "plt.show();\n",
    "\n",
    "grid, xx, yy = plotting.create_grid(search_space.lower, search_space.upper, grid_density=20)\n",
    "\n",
    "points_in_objective_space = f(grid)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=0)\n",
    "plt.xlabel(\"f1\");\n",
    "plt.ylabel(\"f2\");\n",
    "plt.title(\"True Pareto front\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71dd0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_function = MOLocalPenalizationAcquisitionFunction().using(OBJECTIVE)\n",
    "acq_rule = EfficientGlobalOptimization(acq_function, num_query_points=num_query_points)\n",
    "model = build_stacked_independent_objectives_model(initial_data[OBJECTIVE])\n",
    "\n",
    "result = BayesianOptimizer(observer, search_space).optimize(num_steps, initial_data, {OBJECTIVE: model}, acq_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4284db56",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = result.try_get_final_datasets()[OBJECTIVE]\n",
    "models = result.try_get_final_models()[OBJECTIVE]._models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ef5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_query_points = dataset.query_points\n",
    "f1_model_values, _ = models[0].predict(all_query_points)\n",
    "f2_model_values, _ = models[1].predict(all_query_points)\n",
    "\n",
    "points_in_objective_space = tf.concat([f1_model_values, f2_model_values], axis=1)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=num_initial_points)\n",
    "plt.xlabel(\"f1\");\n",
    "plt.ylabel(\"f2\");\n",
    "plt.title(\"Discovered Pareto front\");\n",
    "plt.show();\n",
    "\n",
    "grid, xx, yy = plotting.create_grid(search_space.lower, search_space.upper, grid_density=20)\n",
    "\n",
    "points_in_objective_space = f(grid)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=0)\n",
    "plt.xlabel(\"f1\");\n",
    "plt.ylabel(\"f2\");\n",
    "plt.title(\"True Pareto front\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba712a",
   "metadata": {},
   "source": [
    "## Trieste integ tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17d0851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multi_objective_optimizer_finds_pareto_front_of_the_VLMOP2_function(\n",
    "    num_steps, acquisition_rule, convergence_threshold):\n",
    "    tf.random.set_seed(0)\n",
    "    search_space = Box([-2, -2], [2, 2])\n",
    "\n",
    "    def build_stacked_independent_objectives_model(data: Dataset) -> ModelStack:\n",
    "        gprs = []\n",
    "        for idx in range(2):\n",
    "            single_obj_data = Dataset(\n",
    "                data.query_points, tf.gather(data.observations, [idx], axis=1)\n",
    "            )\n",
    "            variance = tf.math.reduce_variance(single_obj_data.observations)\n",
    "            kernel = gpflow.kernels.Matern52(variance, tf.constant([0.2, 0.2], tf.float64))\n",
    "            gpr = gpflow.models.GPR(single_obj_data.astuple(), kernel, noise_variance=1e-5)\n",
    "            gpflow.utilities.set_trainable(gpr.likelihood, False)\n",
    "            gprs.append((GaussianProcessRegression(gpr), 1))\n",
    "\n",
    "        return ModelStack(*gprs)\n",
    "\n",
    "    observer = mk_observer(VLMOP2().objective(), OBJECTIVE)\n",
    "\n",
    "    initial_query_points = search_space.sample(10)\n",
    "    initial_data = observer(initial_query_points)\n",
    "\n",
    "    model = build_stacked_independent_objectives_model(initial_data[OBJECTIVE])\n",
    "\n",
    "    dataset = (\n",
    "        BayesianOptimizer(observer, search_space)\n",
    "        .optimize(num_steps, initial_data, {OBJECTIVE: model}, acquisition_rule)\n",
    "        .try_get_final_datasets()[OBJECTIVE]\n",
    "    )\n",
    "\n",
    "    # A small log hypervolume difference corresponds to a succesful optimization.\n",
    "    ref_point = get_reference_point(dataset.observations)\n",
    "\n",
    "    obs_hv = Pareto(dataset.observations).hypervolume_indicator(ref_point)\n",
    "    ideal_pf = tf.cast(VLMOP2().gen_pareto_optimal_points(100), dtype=tf.float64)\n",
    "    ideal_hv = Pareto(ideal_pf).hypervolume_indicator(ref_point)\n",
    "\n",
    "    assert tf.math.log(ideal_hv - obs_hv) < convergence_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trieste.acquisition import (\n",
    "    BatchMonteCarloExpectedHypervolumeImprovement,\n",
    "    ExpectedHypervolumeImprovement,\n",
    ")\n",
    "from trieste.acquisition.multi_objective.pareto import Pareto, get_reference_point\n",
    "from trieste.acquisition.optimizer import generate_continuous_optimizer\n",
    "from trieste.acquisition.rule import (\n",
    "    AcquisitionRule,\n",
    "    AsynchronousOptimization,\n",
    "    EfficientGlobalOptimization,\n",
    ")\n",
    "from trieste.bayesian_optimizer import BayesianOptimizer\n",
    "from trieste.data import Dataset\n",
    "from trieste.models.gpflow import GaussianProcessRegression\n",
    "from trieste.models.interfaces import ModelStack\n",
    "from trieste.objectives.multi_objectives import VLMOP2\n",
    "from trieste.objectives.utils import mk_observer\n",
    "from trieste.observer import OBJECTIVE\n",
    "from trieste.space import Box\n",
    "from trieste.types import TensorType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fadbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_params = [\n",
    "    (\n",
    "            15,\n",
    "            EfficientGlobalOptimization(\n",
    "                BatchMonteCarloExpectedHypervolumeImprovement(sample_size=500).using(OBJECTIVE),\n",
    "                num_query_points=2,\n",
    "                optimizer=generate_continuous_optimizer(num_initial_samples=500),\n",
    "            ),\n",
    "            -3.44,\n",
    "    ),\n",
    "    (\n",
    "            10,\n",
    "            EfficientGlobalOptimization(\n",
    "                BatchMonteCarloExpectedHypervolumeImprovement(sample_size=250).using(OBJECTIVE),\n",
    "                num_query_points=4,\n",
    "                optimizer=generate_continuous_optimizer(num_initial_samples=500),\n",
    "            ),\n",
    "            -3.2095,\n",
    "    ),\n",
    "    \n",
    "    \n",
    "    # same as above, but with the new LP acq function\n",
    "    (\n",
    "            15,\n",
    "            EfficientGlobalOptimization(\n",
    "                MOLocalPenalizationAcquisitionFunction().using(OBJECTIVE),\n",
    "                num_query_points=2,\n",
    "                optimizer=generate_continuous_optimizer(num_initial_samples=500),\n",
    "            ),\n",
    "            -3.44,\n",
    "    ),\n",
    "    (\n",
    "            10,\n",
    "            EfficientGlobalOptimization(\n",
    "                MOLocalPenalizationAcquisitionFunction().using(OBJECTIVE),\n",
    "                num_query_points=4,\n",
    "                optimizer=generate_continuous_optimizer(num_initial_samples=500),\n",
    "            ),\n",
    "            -3.2095,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b879ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ip in input_params:\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"input:\", ip)\n",
    "    test_multi_objective_optimizer_finds_pareto_front_of_the_VLMOP2_function(ip[0], ip[1], ip[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c64425",
   "metadata": {},
   "source": [
    "## ZDT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = trieste.space.Box([0, 0], [1, 1])\n",
    "\n",
    "def f1(x):\n",
    "    return tf.reshape(x[:, 0], (-1, 1))\n",
    "\n",
    "def f2(x):\n",
    "    x1 = x[:, 0]\n",
    "    n = tf.cast(tf.shape(x)[-1], tf.float64)\n",
    "    g = 1.0 + tf.reduce_sum(x[:, 1:], axis=1) * 9.0 / (n - 1.0)\n",
    "    h = 1 - tf.sqrt(x1 / g) - x1 / g * tf.sin(10.0 * math.pi * x1)\n",
    "    return h[:, None]\n",
    "\n",
    "def f(x):\n",
    "    return tf.concat([f1(x), f2(x)], axis=-1)\n",
    "\n",
    "observer = mk_observer(f, OBJECTIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a74913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_initial_points = 5\n",
    "initial_query_points = search_space.sample(num_initial_points)\n",
    "initial_data = observer(initial_query_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6be8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_query_points = 5 # 10 runs out of memory and kills the kernel\n",
    "num_steps = 20\n",
    "\n",
    "model = build_stacked_independent_objectives_model(initial_data[OBJECTIVE])\n",
    "\n",
    "acq_function = BatchMonteCarloExpectedHypervolumeImprovement(sample_size=250).using(OBJECTIVE)\n",
    "acq_rule = EfficientGlobalOptimization(acq_function, num_query_points=num_query_points)\n",
    "\n",
    "result = BayesianOptimizer(observer, search_space).optimize(num_steps, initial_data, {OBJECTIVE: model}, acq_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be08fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = result.try_get_final_datasets()[OBJECTIVE]\n",
    "models = result.try_get_final_models()[OBJECTIVE]._models\n",
    "\n",
    "all_query_points = dataset.query_points\n",
    "f1_model_values, _ = models[0].predict(all_query_points)\n",
    "f2_model_values, _ = models[1].predict(all_query_points)\n",
    "\n",
    "points_in_objective_space = tf.concat([f1_model_values, f2_model_values], axis=1)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=num_initial_points)\n",
    "plt.xlabel(\"f1\");\n",
    "plt.ylabel(\"f2\");\n",
    "plt.title(\"Discovered Pareto front\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_query_points = 5\n",
    "num_steps = 20\n",
    "\n",
    "acq_function = MOLocalPenalizationAcquisitionFunction().using(OBJECTIVE)\n",
    "acq_rule = EfficientGlobalOptimization(acq_function, num_query_points=num_query_points)\n",
    "model = build_stacked_independent_objectives_model(initial_data[OBJECTIVE])\n",
    "\n",
    "result = BayesianOptimizer(observer, search_space).optimize(num_steps, initial_data, {OBJECTIVE: model}, acq_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc7a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = result.try_get_final_datasets()[OBJECTIVE]\n",
    "models = result.try_get_final_models()[OBJECTIVE]._models\n",
    "\n",
    "all_query_points = dataset.query_points\n",
    "f1_model_values, _ = models[0].predict(all_query_points)\n",
    "f2_model_values, _ = models[1].predict(all_query_points)\n",
    "\n",
    "points_in_objective_space = tf.concat([f1_model_values, f2_model_values], axis=1)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=num_initial_points, figsize=(12,12))\n",
    "\n",
    "from matplotlib.pyplot import cm\n",
    "colors = cm.rainbow(np.linspace(0, 1, num_steps))\n",
    "\n",
    "for i in range(0, num_steps):\n",
    "    start = num_initial_points + i*num_query_points\n",
    "    end = num_initial_points + (i+1)*num_query_points\n",
    "    plt.scatter(f1_model_values[start:end, :], f2_model_values[start:end, :], color=colors[i])\n",
    "\n",
    "plt.xlabel(\"f1\");\n",
    "plt.ylabel(\"f2\");\n",
    "plt.title(\"Discovered Pareto front\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec104e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 100\n",
    "\n",
    "from trieste.acquisition.function.multi_objective import ExpectedHypervolumeImprovement\n",
    "\n",
    "acq_function = ExpectedHypervolumeImprovement().using(OBJECTIVE)\n",
    "acq_rule = EfficientGlobalOptimization(acq_function)\n",
    "model = build_stacked_independent_objectives_model(initial_data[OBJECTIVE])\n",
    "\n",
    "result = BayesianOptimizer(observer, search_space).optimize(num_steps, initial_data, {OBJECTIVE: model}, acq_rule)\n",
    "\n",
    "\n",
    "dataset = result.try_get_final_datasets()[OBJECTIVE]\n",
    "models = result.try_get_final_models()[OBJECTIVE]._models\n",
    "\n",
    "all_query_points = dataset.query_points\n",
    "f1_model_values, _ = models[0].predict(all_query_points)\n",
    "f2_model_values, _ = models[1].predict(all_query_points)\n",
    "\n",
    "points_in_objective_space = tf.concat([f1_model_values, f2_model_values], axis=1)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=num_initial_points, figsize=(12,12))\n",
    "\n",
    "# from matplotlib.pyplot import cm\n",
    "# colors = cm.rainbow(np.linspace(0, 1, num_steps))\n",
    "\n",
    "# for i in range(0, num_steps):\n",
    "#     start = num_initial_points + i*num_query_points\n",
    "#     end = num_initial_points + (i+1)*num_query_points\n",
    "#     plt.scatter(f1_model_values[start:end, :], f2_model_values[start:end, :], color=colors[i])\n",
    "\n",
    "plt.xlabel(\"f1\");\n",
    "plt.ylabel(\"f2\");\n",
    "plt.title(\"Discovered Pareto front\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b4834d",
   "metadata": {},
   "source": [
    "## Hartmann and Ackley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e767e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trieste.objectives.single_objectives import hartmann_6, ackley_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4989ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ackley funciton in Trieste is defined over 5d domain, and we want\n",
    "def ackley_6(x: TensorType) -> TensorType:\n",
    "    tf.debugging.assert_shapes([(x, (..., 6))])\n",
    "    \n",
    "    x_5d = x[..., :-1]\n",
    "\n",
    "    return ackley_5(x_5d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d7100",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = trieste.space.Box([0]*6, [1]*6)\n",
    "\n",
    "def f(x):\n",
    "    return tf.concat([hartmann_6(x), ackley_6(x)], axis=-1)\n",
    "\n",
    "observer = mk_observer(f, OBJECTIVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a095c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_initial_points = 5\n",
    "initial_query_points = search_space.sample(num_initial_points)\n",
    "initial_data = observer(initial_query_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23996fce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_query_points = 5\n",
    "num_steps = 20\n",
    "\n",
    "model = build_stacked_independent_objectives_model(initial_data[OBJECTIVE])\n",
    "\n",
    "acq_function = BatchMonteCarloExpectedHypervolumeImprovement(sample_size=250).using(OBJECTIVE)\n",
    "acq_rule = EfficientGlobalOptimization(acq_function, num_query_points=num_query_points)\n",
    "\n",
    "result = BayesianOptimizer(observer, search_space).optimize(num_steps, initial_data, {OBJECTIVE: model}, acq_rule)\n",
    "\n",
    "dataset = result.try_get_final_datasets()[OBJECTIVE]\n",
    "models = result.try_get_final_models()[OBJECTIVE]._models\n",
    "\n",
    "all_query_points = dataset.query_points\n",
    "f1_model_values, _ = models[0].predict(all_query_points)\n",
    "f2_model_values, _ = models[1].predict(all_query_points)\n",
    "\n",
    "points_in_objective_space = tf.concat([f1_model_values, f2_model_values], axis=1)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=num_initial_points, figsize=(12,12))\n",
    "\n",
    "# from matplotlib.pyplot import cm\n",
    "# colors = cm.rainbow(np.linspace(0, 1, num_steps))\n",
    "\n",
    "# for i in range(0, num_steps):\n",
    "#     start = num_initial_points + i*num_query_points\n",
    "#     end = num_initial_points + (i+1)*num_query_points\n",
    "#     plt.scatter(f1_model_values[start:end, :], f2_model_values[start:end, :], color=colors[i])\n",
    "\n",
    "plt.xlabel(\"Hartmann\");\n",
    "plt.ylabel(\"Ackley\");\n",
    "plt.title(\"BatchMC EHVI\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afa7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_query_points = 5\n",
    "num_steps = 20\n",
    "\n",
    "acq_function = MOLocalPenalizationAcquisitionFunction().using(OBJECTIVE)\n",
    "acq_rule = EfficientGlobalOptimization(acq_function, num_query_points=num_query_points)\n",
    "model = build_stacked_independent_objectives_model(initial_data[OBJECTIVE])\n",
    "\n",
    "result = BayesianOptimizer(observer, search_space).optimize(num_steps, initial_data, {OBJECTIVE: model}, acq_rule)\n",
    "\n",
    "dataset = result.try_get_final_datasets()[OBJECTIVE]\n",
    "models = result.try_get_final_models()[OBJECTIVE]._models\n",
    "\n",
    "all_query_points = dataset.query_points\n",
    "f1_model_values, _ = models[0].predict(all_query_points)\n",
    "f2_model_values, _ = models[1].predict(all_query_points)\n",
    "\n",
    "points_in_objective_space = tf.concat([f1_model_values, f2_model_values], axis=1)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=num_initial_points, figsize=(12,12))\n",
    "\n",
    "# from matplotlib.pyplot import cm\n",
    "# colors = cm.rainbow(np.linspace(0, 1, num_steps))\n",
    "\n",
    "# for i in range(0, num_steps):\n",
    "#     start = num_initial_points + i*num_query_points\n",
    "#     end = num_initial_points + (i+1)*num_query_points\n",
    "#     plt.scatter(f1_model_values[start:end, :], f2_model_values[start:end, :], color=colors[i])\n",
    "\n",
    "plt.xlabel(\"Hartmann\");\n",
    "plt.ylabel(\"Ackley\");\n",
    "plt.title(\"MO LP\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 100\n",
    "\n",
    "from trieste.acquisition.function.multi_objective import ExpectedHypervolumeImprovement\n",
    "\n",
    "acq_function = ExpectedHypervolumeImprovement().using(OBJECTIVE)\n",
    "acq_rule = EfficientGlobalOptimization(acq_function)\n",
    "model = build_stacked_independent_objectives_model(initial_data[OBJECTIVE])\n",
    "\n",
    "result = BayesianOptimizer(observer, search_space).optimize(num_steps, initial_data, {OBJECTIVE: model}, acq_rule)\n",
    "\n",
    "\n",
    "dataset = result.try_get_final_datasets()[OBJECTIVE]\n",
    "models = result.try_get_final_models()[OBJECTIVE]._models\n",
    "\n",
    "all_query_points = dataset.query_points\n",
    "f1_model_values, _ = models[0].predict(all_query_points)\n",
    "f2_model_values, _ = models[1].predict(all_query_points)\n",
    "\n",
    "points_in_objective_space = tf.concat([f1_model_values, f2_model_values], axis=1)\n",
    "plotting.plot_mobo_points_in_obj_space(points_in_objective_space, num_init=num_initial_points, figsize=(12,12))\n",
    "\n",
    "# from matplotlib.pyplot import cm\n",
    "# colors = cm.rainbow(np.linspace(0, 1, num_steps))\n",
    "\n",
    "# for i in range(0, num_steps):\n",
    "#     start = num_initial_points + i*num_query_points\n",
    "#     end = num_initial_points + (i+1)*num_query_points\n",
    "#     plt.scatter(f1_model_values[start:end, :], f2_model_values[start:end, :], color=colors[i])\n",
    "\n",
    "plt.xlabel(\"Hartmann\");\n",
    "plt.ylabel(\"Ackley\");\n",
    "plt.title(\"EHVI\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f12f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
